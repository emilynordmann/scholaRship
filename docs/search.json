[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"scholaRship collection tutorials engage scholarship teaching learning using quantitative methods R. written Learning, Teaching, Scholarship focused academics: Emily Nordmann, James Bartlett Gaby Mahrholz School Psychology Neuroscience, University Glasgow, Mitchum Bock, Eilidh Jack, Craig Alexander, School Mathematics Statistics, University Glasgow, Jill MacKay, University Edinburgh.book considered living document. tutorials added time developed content structure new existing tutorials may updated.Contact: Emily Nordmann (Emily.Nordmann@glasgow.ac.uk)","code":""},{"path":"intro.html","id":"intro","chapter":"1 Introduction","heading":"1 Introduction","text":"Getting started scholarship teaching learning can difficult. majority academics whose subject expertise involve learning teaching, first hurdle figuring questions can ask answer (indeed interested ) can toughest one push past.settled area inquiry, may find appropriate methodologies investigate questions ones trained . quantitatively-minded researchers, availability data can feel like simultaneous feast famine - may access huge amounts data learning analytics standard student records able use almost none research purposes due need opt-consent. consent obtained, may small, non-representative samples, non-random attrition, /concerns making data openly available.Finally, data can seriously messy: missing data, data multiple sources different structures labels, data different academic years course structures assessments changed, anonymised data, aggregated data.sounds familiar, book .tutorial book contain:short summary evidence-base problem investigation promote engagement SoTL literature;Real1 data drawn commonly available sources Moodle, Turnitin, Microsoft Forms, Echo360;walkthrough clean wrangle data using predominantly tidyverse approach;walkthrough analyse interpret, analysis, alongside honest discussion limitations approach used.","code":""},{"path":"intro.html","id":"planned-tutorials","chapter":"1 Introduction","heading":"1.1 Planned tutorials","text":"following tutorials planned happy take suggestions - please e-mail Emily.Nordmann@glasgow.ac.uk.Analysing impact whether students check feedback Turnitin Feedback Studio subsequent assessment performance.Creating exam board moderation reports using RUsing Moodle logs predict engagement retention","code":""},{"path":"intro.html","id":"expectations-of-prior-knowledge","chapter":"1 Introduction","heading":"1.2 Expectations of prior knowledge","text":"","code":""},{"path":"intro.html","id":"r-and-rstudio","chapter":"1 Introduction","heading":"1.2.1 R and RStudio","text":"Minimal prior knowledge R RStudio assumed throughout book. functions code used explained, however, assume reader understands :Install R RStudioInstall R RStudioNavigate RStudioNavigate RStudioSet working directory appropriatelySet working directory appropriatelyInstall load packagesInstall load packagesWrite execute codeWrite execute codeEach chapter start overview expected prior knowledge along resources recap necessary.","code":""},{"path":"intro.html","id":"research-methods-and-statistics","chapter":"1 Introduction","heading":"1.2.2 Research methods and statistics","text":"assume basic level competency research methods statistics. However, also recognise many researchers still less familiar modern approaches mixed effects models provide appropriate level explanation resources necessary.","code":""},{"path":"creating-synthetic-datasets.html","id":"creating-synthetic-datasets","chapter":"2 Creating synthetic datasets","heading":"2 Creating synthetic datasets","text":"Lead author: James Bartlett","code":""},{"path":"creating-synthetic-datasets.html","id":"introduction","chapter":"2 Creating synthetic datasets","heading":"2.1 Introduction","text":"scholarship teaching learning, might analyse data sources like virtual learning environments student characteristics. Student agreements normally allow educators analyse data purposes internally improving education experiences, want disseminate findings wider audience, need gain ethical approval students use data additional purposes. Even ethical approval, might additional concerns around privacy anonymity data contain sensitive personal information. data sharing practices become routine, important contribute scholarly progress maintaining participant anonymity. tutorial, demonstrate can create synthetic data sets strategy sharing primary data present ethical issues.Synthetic data mimics properties original data closely possible, retaining distribution grades sample. means can retain underlying statistical properties variables, \"individual participants\" longer represent original cases, meaning risk identification much lower. R package synthpop (Nowok et al., 2016) creates synthetic data sampling probability distribution best suited variables data set. precise technical details beyond scope tutorial, refer interested readers Nowok et al. information.important evaluate project individually judge whether can ethically share research data, Meyer (2018) provides practical tips:Wherever possible, get informed consent participants retain share data.Wherever possible, get informed consent participants retain share data.promise destroy never share data. Often researchers reassure ethical review boards data never shared beyond research team, providing appropriate , can simply ask participants consent data shared.promise destroy never share data. Often researchers reassure ethical review boards data never shared beyond research team, providing appropriate , can simply ask participants consent data shared.thoughtful considering risks re-identification.thoughtful considering risks re-identification.Assuming receive consent data sharing, likelihood identifying individual participants motivates synthetic data tutorial. Even exclude identifiable information like names email addresses, participants re-identified combining common demographic variables ethnicity, date birth, sex might want share related research question. risk re-identification may even higher participants know . example, students might know studied cohort able identify data set recognise participants relative details. Therefore, want share data part scholarship receive consent participants , important think whether variables want share used identify participants whether providing synthetic data set original data appropriate. See Meyer (2018) details ethical data sharing.tutorial, demonstrate create synthetic data set using synthpop package R. Quintana (2020) previously written accessible tutorial package recommend focuses biomedical science data. tutorial use data student's academic procrastination resonate closely scholarship teaching learning.","code":""},{"path":"creating-synthetic-datasets.html","id":"dunn-2014-replication","chapter":"2 Creating synthetic datasets","heading":"2.1.1 Dunn (2014) Replication","text":"data set use unpublished replication attempt Dunn (2014). Dunn wanted understand impact motivation statistics anxiety students' academic procrastination. sample included graduate students online course. wanted replicate study see observe similar findings response COVID-19 pandemic face--face students forced study online. Dunn replication perfect demonstrate synthetic data set includes range data types included open data consent forms, meaning can openly compare properties data set.research question : intrinsic motivation, academic self-regulation, statistics anxiety influence students' passive procrastination? expected intrinsic motivation self-regulation negative predictors, whereas expected statistics anxiety positive predictor passive procrastination. study included following variables:General strategies learning (GSL; GSL) - modified subscale Motivated Strategies Learning Questionnaire (MSLQ) measures academic self-regulation. Measured 1-7 scale, higher values meaning higher self-regulation.General strategies learning (GSL; GSL) - modified subscale Motivated Strategies Learning Questionnaire (MSLQ) measures academic self-regulation. Measured 1-7 scale, higher values meaning higher self-regulation.Intrinsic motivation (Intrinsic) - subscale MSLQ measures intrinsic motivation inherent joy people find task. Measured 1-7 scale, higher values meaning higher intrinsic motivation.Intrinsic motivation (Intrinsic) - subscale MSLQ measures intrinsic motivation inherent joy people find task. Measured 1-7 scale, higher values meaning higher intrinsic motivation.Statistical Anxiety Rating Scale (STARS; STARS) - measure statistics anxiety included statistics test class anxiety subscale. Measured 1-5 scale, higher values meaning higher statistics anxiety.Statistical Anxiety Rating Scale (STARS; STARS) - measure statistics anxiety included statistics test class anxiety subscale. Measured 1-5 scale, higher values meaning higher statistics anxiety.Procrastination Assessment Scale Students (PASS; PASS) - measure passive procrastination keeping writing assignments studying exams. Measured 1-5 scale higher scores meaning greater procrastination, scale uses sum items creating possible range 6-30.Procrastination Assessment Scale Students (PASS; PASS) - measure passive procrastination keeping writing assignments studying exams. Measured 1-5 scale higher scores meaning greater procrastination, scale uses sum items creating possible range 6-30.","code":""},{"path":"creating-synthetic-datasets.html","id":"prior-knowledge","chapter":"2 Creating synthetic datasets","heading":"2.1.2 Prior knowledge","text":"complete tutorial need following prior knowledge - recap links point additional materials cover detail):install load packages R (recap)set working directory run code R (recap)() use pipe %>% operator (recap)conceptual understanding linear regression (recap)","code":""},{"path":"creating-synthetic-datasets.html","id":"synthpop-setup","chapter":"2 Creating synthetic datasets","heading":"2.1.3 Set-up","text":"demonstrate synthpop package, explore original data set modelling.Download Dunn-replication.csv save folder named data working directory.run code load required packages (may require installation) data.","code":"\nlibrary(tidyverse) # Collection of functions for data wrangling and visualisation\nlibrary(performance) # Functions for assessing statistical models\nlibrary(effectsize) # Functions for calculating effect sizes\nlibrary(synthpop) # Package to create our synthetic data set later\n\n# Two functions to make prettier html tables\nlibrary(knitr)\nlibrary(kableExtra)\n\nreal_data <- read_csv(\"data/Dunn-replication.csv\") %>% \n  select(-user_id, -SelfEfficacy, -HelpSeeking) # omit some columns we don't need"},{"path":"creating-synthetic-datasets.html","id":"original-dataset-analyses","chapter":"2 Creating synthetic datasets","heading":"2.2 Original dataset analyses","text":"address research question using model Dunn (2014), want use linear regression PASS outcome three predictors GSL, intrinsic motivation, statistics anxiety.function lm() constructs linear modelThe formula takes form outcome ~ predictor1 + predictor2 etc.first save results regression object model pass object summary() function explore model results:replication different setting, results pretty close Dunn (2014). Overall, significant model explains 18% (adj. \\(R^2\\) = 0.16) variance passive procrastination. Similar Dunn, GSL significant negative predictor passive procrastination, 1 unit increase GSL associated 1.77 decrease passive procrastination. Intrinsic motivation non-significant weak negative predictor. Interestingly, statistics anxiety significant predictor Dunn, significant positive predictor replication, 1 unit increase STARS associated 1.69 increase passive procrastination. words, passive procrastination tended increase higher levels statistics anxiety lower levels GSL.values original units measurement, can also report standardised coefficients express values standard deviations, consistent Dunn reported results. can standardising predictors entering model, can use handy standardize_parameters() function effectsize package get 95% confidence intervals . , save results table add estimates Dunn (2014) comparison.code:Calculates standardized coefficients saves object named tableCreates vector coefficients original Dunn studyAdds vector column tableMakes nice looking table using kable - note table output might look slightly different bookdown package use write book applies additional formatting.\nTable 2.1: Standardised Beta coefficients 95% confidence interval (CI) replication data compared Dunn (2014).\ncomparison, coefficient STARS larger Dunn, coefficients GSL intrinsic motivation smaller. findings largely consistent though, coefficients direction within 95% CI estimates. Despite intrinsic motivation significant predictor, findings consistent hypotheses largely replicate findings Dunn.final check, important make sure model results consistent assumptions linear regression. great package called performance includes helper functions like check_model(). can concisely check model assumptions:Although bottom right plot normality residuals quite capturing peak normal distribution, nothing suggest warning signs model.findings assumptions order, know real data set telling us. Now, time create synthetic data set using synthpop package see close replicates features.","code":"\n# One outcome, three predictors\nmodel <- lm(PASS ~ GSL + Intrinsic + STARS,\n            data = real_data)\n\n(model_results <- summary(model)) # surround with brackets to both print and save## \n## Call:\n## lm(formula = PASS ~ GSL + Intrinsic + STARS, data = real_data)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -14.8588  -3.4830   0.0803   3.2853   9.9100 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  23.6386     3.0068   7.862  3.2e-12 ***\n## GSL          -1.7677     0.4698  -3.762 0.000275 ***\n## Intrinsic    -0.1780     0.5160  -0.345 0.730767    \n## STARS         1.6926     0.5961   2.840 0.005408 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.405 on 107 degrees of freedom\n## Multiple R-squared:  0.1815, Adjusted R-squared:  0.1586 \n## F-statistic: 7.911 on 3 and 107 DF,  p-value: 8.154e-05\n#1. Use the standardize_parameters function\n#2. Select rows 2-4, ignoring the intercept\n#3. Save in a data frame\n#4. Drop the 95% CI column as it's just descriptive \n\ntable <- standardize_parameters(model) %>%\n  slice(2:7) %>%\n  data.frame() %>%\n  select(-CI)\n\n# Manually save values from the original Dunn study for comparison\ndunn <- c(-0.55, # GSL\n          -0.17, # Intrinsic\n          0.15) # STARS\n\n# Add these values to our table above\ntable$dunn <- dunn\n\n# Use the kable and kableextra functions to create a nicer looking table \nkable(table, \n      digits = 2, \n      format = \"html\", \n      col.names = c(\"Parameter\", \"Beta\", \"Lower 95% CI\", \"Upper 95% CI\", \"Beta from Dunn (2014)\"), \n      caption = \"Standardised Beta coefficients and their 95% confidence interval (CI) in the replication data compared to Dunn (2014).\") %>% \n  kable_styling()\ncheck_model(model)"},{"path":"creating-synthetic-datasets.html","id":"synthesise-with-synthpop","chapter":"2 Creating synthetic datasets","heading":"2.3 Synthesise with synthpop","text":"synthpop package (Nowok et al., 2016) aims mimic observed data preserve relationship variables. authors developed package work around limitations working vast data coming national statistical agencies. population level data sets can provide important insights, granularity data rightly leads privacy concerns identifiable participants , restricting access data. Working higher education data, can face similar concerns. access student level data can provide important insights, often access share data confidentiality constraints. synthetic data can useful.Packages like synthpop attempt reconstruct data set sampling probability distributions relevant type data working . means properties variables relationships retained closely possible. Sometimes less accurate, explore factors keep mind later .","code":""},{"path":"creating-synthetic-datasets.html","id":"preparing-the-data-set","chapter":"2 Creating synthetic datasets","heading":"2.3.1 Preparing the data set","text":"creating synthetic data set important check data determine number type variables, well much missing data () can using codebook.syn() function.Whilst output might look useful, actually missing lot information dataset individual variables quite right format.first step convert object data frame. used \"tidyverse\" family packages, data saved something called tibble. Tibbles similar data frames, tweaks work better tidyverse (see tibble chapter R Data Science book; Wickham & Grolemund, 2017). Although tibbles can useful within tidyverse framework, can occasionally cause problems. found hard way writing tutorial try use data without converting data frame, get cryptic error message Error tab.obs[[]] + tab.syn[[]] : non-conformable array took us hour figure . reading forum highlighting tibbles caused similar problem another package tried converting data frame first solved issue.second step ensure character variables set factors whilst data columns text data, informative text represents different categories. creating synthetic data set, function works probability distribution using original data, setting characters factors establishes number unique groups per variable.Now, repeat codebook function, get added details informing us number levels per variable factors data range numeric variables. data set, missing data, , central columns inform us number percent missing values, also something can estimated part synthetic data function.","code":"\ncodebook.syn(real_data)## $tab\n##           variable     class nmiss perctmiss ndistinct details\n## 1              age   numeric     0         0        16        \n## 2           gender character     0         0         4        \n## 3 degree_programme character     0         0         4        \n## 4              GSL   numeric     0         0        24        \n## 5        Intrinsic   numeric     0         0        18        \n## 6            STARS   numeric     0         0        25        \n## 7             PASS   numeric     0         0        20        \n## \n## $labs\n## NULL\n# Resave real_data as a data frame instead of a tibble\nreal_data <- as.data.frame(real_data)\n\n# Convert gender to a factor\nreal_data$gender <- as.factor(real_data$gender)\n\n# Convert degree programme to a factor\nreal_data$degree_programme <- as.factor(real_data$degree_programme)\ncodebook.syn(real_data)## $tab\n##           variable   class nmiss perctmiss ndistinct           details\n## 1              age numeric     0         0        16    Range: 18 - 50\n## 2           gender  factor     0         0         4 See table in labs\n## 3 degree_programme  factor     0         0         4 See table in labs\n## 4              GSL numeric     0         0        24  Range: 1.6 - 6.8\n## 5        Intrinsic numeric     0         0        18 Range: 2.5 - 6.75\n## 6            STARS numeric     0         0        25  Range: 1.875 - 5\n## 7             PASS numeric     0         0        20     Range: 6 - 30\n## \n## $labs\n## $labs$gender\n##                  label\n## 1               Female\n## 2                 Male\n## 3           Non-binary\n## 4 Prefer not to answer\n## \n## $labs$degree_programme\n##   label\n## 1    BA\n## 2   BSc\n## 3    MA\n## 4   MSc"},{"path":"creating-synthetic-datasets.html","id":"subset-the-data","chapter":"2 Creating synthetic datasets","heading":"2.3.2 Subset the data","text":"Previously, mentioned synthpop match features original data closely possible, can less accurate. One factor associated ratio number participants number variables data set. synthetic data set tries retain association variables, larger number variables, combinations function must consider. enough participants, synthpop provide warning number participants recommends based number variables data set. 100 + 10 * number variables. , two variables, recommend 120 participants, eight variables 180 participants etc. fewer participants recommended, estimation process might less precise.demonstration, first create limited data set two variables show works, scale full data set. following code, set seed make analyses reproducible. function set.seed() controls random number generator - using functions use randomness, running set.seed() ensure get result time run function (many cases may want ). estimation synthetic data set based simulations, set seed get results tutorial.know GSL strongest predictor original data, limit results just predicting academic procrastination GSL create synthetic data set using syn() function.Now, synthetic data set saved object environment, synthpop includes function save new data current working directory. following function takes synthetic data object, like file called, file type want saved :ran code save synthetic data set, see three new files working directory. . RData object can reload R. choosing .csv file, also spreadsheet containing data analyse software read R. Finally, .txt file information synthetic data process like name original data file, seed used, variables.","code":"\n# Set a seed for reproducible analyses\nmy_seed <- 2018\n\n# limit the real data to just two variables \nshort_data <- real_data %>% \n  select(PASS, GSL)\n\n# Save the synthetic data using the reproducible seed from above\nsynth_data <- syn(short_data, \n                   seed = my_seed)## CAUTION: Your data set has fewer observations (111) than we advise.\n## We suggest that there should be at least 120 observations\n## (100 + 10 * no. of variables used in modelling the data).\n## Please check your synthetic data carefully with functions\n## compare(), utility.tab(), and utility.gen().\n## \n## Synthesis\n## -----------\n##  PASS GSL\nwrite.syn(synth_data, \n          filename = \"synthetic_Dunn_data\", \n          filetype = \"csv\")## Synthetic data exported as csv file(s).\n## Information on synthetic data written to\n##   C:/Users/staff/OneDrive - University of Glasgow/Teaching/psyteachR/scholaRship/book/synthesis_info_synthetic_Dunn_data.txt"},{"path":"creating-synthetic-datasets.html","id":"compare-data-sets","chapter":"2 Creating synthetic datasets","heading":"2.3.3 Compare data sets","text":"Now synthetic data, synthpop useful functions compare new data observed data. example, can compare distribution values two data sets see well reconstructed values. stat argument, can choose either \"counts\" \"percents\" show histogram frequency percentage values, depending prefer interpret.can see two histograms limited selection two variables. dark blue, frequency observations observed data, light blue, frequency observations synthetic data. perfect match, observed values higher synthetic, synthetic values higher observed. never going perfect, trying capture features closely possible, different underlying distributions can produce relationships variables.histograms, default settings utility measures. statistics summarise closely synthetic data compares observed data, assuming synthesis model correct. three default results pMSE (propensity score mean-squared error), S_pMSE (standardised measure pMSE), df (degrees freedom Chi-Square tests). many utility measures can request using utility.stats argument. explore measures available, read documentation entering help(\"utility.tab\") console.want fall statistics rabbit role, refer Raab et al. (2021) Snoke et al. (2018) test different utility measures. brief overview, general/global specific/narrow utility measures. Global measures attempt capture well synthesis process reconstructs relationships across whole data set rather result one specific statistical model. output , pMSE one measure. Propensity scores work combining two data sets calculating probability observation comes synthetic data. means propensity score mean-squared error (pMSE) measures error associated process, higher values meaning greater error. closer 0 better, means highest utility hard distinguish two data sets. away 0, easier distinguish two data sets. values small, nothing worry .hand, narrow measures compare models data sets, closely regression coefficients replicated. lm.synds() function synthpop creates linear model using synthetic data sets, can refit using observed data compare different .following code, first create simple linear regression model using PASS outcome GSL single predictor. save object use compare() function .bunch output dissect , start plot visual overview. Similar last compare() output, observed data displayed dark blue synthetic data displayed light blue. plot shows point estimate confidence interval regression coefficient Z value. Visually, looks pretty good. synthetic data estimate slightly smaller, confidence intervals largely overlap.Now initial impression, break output table. informing model fitted, summary model coefficients synthetic observed data, difference , much confidence intervals overlap. intercept, difference -0.46 GSL coefficient, difference 0.10. quite small, keep mind original units measurement, need interpret differences relative measures. Reinforcing visual interpretation, confidence intervals largely overlap, approximately 93% coverage parameters.Finally, Chi-Square test assumes synthetic data model compatible observed data model. essence, null hypothesis difference two models. Acknowledging limitations null hypothesis significance testing, smaller p-value, incompatible two models . p-value close 1, suggesting significant difference two models. p-value much smaller, traditional threshold .05, suspect synthetic data process capture relationships observed data.summarise smaller selection procedure, limited data set two variables: predicting PASS GSL scores. created synthetic data set using synthpop package explored general narrow utility measures. types measures showed synthetic data set good job capturing properties observed data. means share synthetic data set concerns sharing original observed data set. Just remember clearly label synthetic data set fake data set inform readers replaced observed data.","code":"\ncompare(synth_data, # synthetic data object\n        short_data, # original data\n        stat = \"counts\") # Choice of counts or percents## \n## Comparing counts observed with synthetic\n## \n## \n## Selected utility measures:\n##          pMSE   S_pMSE df\n## PASS 0.000207 0.091919  4\n## GSL  0.002052 0.911044  4\n# Linear model equivalent in synthetic data, one outcome and one predictor\ns_lm <- lm.synds(PASS ~ GSL,\n                 data = synth_data)\n\ncompare(s_lm, # saved object from above for lm applied to synthetic data\n        short_data) # original data## \n## Call used to fit models to the data:\n## lm.synds(formula = PASS ~ GSL, data = synth_data)\n## \n## Differences between results based on synthetic and observed data:\n##             Synthetic  Observed       Diff Std. coef diff CI overlap\n## (Intercept) 27.856804 28.319159 -0.4623549     -0.2619675  0.9331703\n## GSL         -1.497014 -1.598289  0.1012751      0.2409324  0.9385365\n## \n## Measures for one synthesis and 2 coefficients\n## Mean confidence interval overlap:  0.9358534\n## Mean absolute std. coef diff:  0.25145\n## \n## Mahalanobis distance ratio for lack-of-fit (target 1.0): 0.04\n## Lack-of-fit test: 0.07152817; p-value 0.9649 for test that synthesis model is compatible \n## with a chi-squared test with 2 degrees of freedom.\n## \n## Confidence interval plot:"},{"path":"creating-synthetic-datasets.html","id":"full-data-set","chapter":"2 Creating synthetic datasets","heading":"2.3.4 Full data set","text":"Now taken close look limited selection variables, scale things see synthpop looks like variable types relationships consider. go back using original real_data file seven variables. first step using syn() function create new synthetic data set. already processed data set reducing number variables, remember check using tibble whether character variables need converting factors.working amount data 111 participants trying reconstruct variables. Remember synthetic data process based sampling appropriate probability distribution, package recommends minimum number participants (100 + 10 * number predictors). smaller selection, close recommendation two predictors least 120 participants. However, larger selection, away recommendation now least 170 participants. Keep mind checking utility measures.Next, compare two data sets see close reconstructed variables:output longer since now seven variables reconstruct instead smaller selection two. can also see character variables look like since smaller selection contained two numeric variables. demographic information omitted smaller selection, can now see age, gender, participant's degree programme., variables interest use next multiple linear regression, using PASS (academic procrastination) outcome three predictors intrinsic motivation, GSL (general strategies learning), STARS (statistics test anxiety). final table general utility measures see well synthetic data set captured features observed data set. Remember pMSE error associated classifying data coming synthetic observed data set, values 0 indicating greater error.use function create linear model synthetic data set, use compare() function see model performs data set narrow utility measures:Starting visual interpretation, synthetic (light blue) observed (dark blue) estimates pretty close. GSL strong negative predictor, STARS moderate positive predictor, intrinsic motivation weak predictor PASS hovering around zero. confidence intervals overlap quite closely smaller selection, look precise statistics moment.Moving table estimates, now four parameters check. coefficients synthetic data set, observed data set, difference . Remember values unstandardised original units measurement, judge differences relative. Compared smaller selection, harder time reconstructing intercept, performance OK three predictors. Supporting visual inspection, confidence interval coverage lower smaller selection, still captures main features. intrinsic motivation interval worst, STARS interval best. Now parameters, can also helpful look mean overlap across confidence intervals, 68% case. poorer performance probably due smaller recommended sample size compared smaller selection.Finally, can look Chi-Square test assumes synthetic data model compatible observed data model. Smaller p-values suggest greater incompatibility two models. larger selection, also statistically significant, suggesting narrow utility performance ideal, inconsistent observed data.","code":"\nsynth_data2 <- syn(real_data, # return to using the original larger data set\n                   seed = my_seed) # use same seed as above ## CAUTION: Your data set has fewer observations (111) than we advise.\n## We suggest that there should be at least 170 observations\n## (100 + 10 * no. of variables used in modelling the data).\n## Please check your synthetic data carefully with functions\n## compare(), utility.tab(), and utility.gen().\n## \n## Synthesis\n## -----------\n##  age gender degree_programme GSL Intrinsic STARS PASS\ncompare(synth_data2, \n        real_data, \n        stat = \"counts\")## \n## Comparing counts observed with synthetic\n## \n## Press return for next variable(s): \n## \n## Selected utility measures:\n##                      pMSE   S_pMSE df\n## age              0.003145 2.792530  2\n## gender           0.000425 0.251701  3\n## degree_programme 0.003070 1.817685  3\n## GSL              0.001869 0.829618  4\n## Intrinsic        0.000741 0.329097  4\n## STARS            0.004231 1.878619  4\n## PASS             0.002649 1.175969  4\n# Second linear model using the full three predictors\ns_lm2 <- lm.synds(PASS ~ GSL + Intrinsic + STARS,\n                 data = synth_data2)\n\n(synth_compare2 <- compare(s_lm2, # New full multiple linear regression model\n        real_data)) # Full observed data file with our 7 variables## \n## Call used to fit models to the data:\n## lm.synds(formula = PASS ~ GSL + Intrinsic + STARS, data = synth_data2)\n## \n## Differences between results based on synthetic and observed data:\n##             Synthetic   Observed       Diff Std. coef diff CI overlap\n## (Intercept) 27.316140 23.6386257  3.6775144      1.2230587  0.6879895\n## GSL         -2.308385 -1.7676992 -0.5406860     -1.1508323  0.7064149\n## Intrinsic   -1.002581 -0.1780281 -0.8245529     -1.5979280  0.5923578\n## STARS        2.280006  1.6926311  0.5873745      0.9853746  0.7486243\n## \n## Measures for one synthesis and 4 coefficients\n## Mean confidence interval overlap:  0.6838466\n## Mean absolute std. coef diff:  1.239298\n## \n## Mahalanobis distance ratio for lack-of-fit (target 1.0): 1.92\n## Lack-of-fit test: 7.683872; p-value 0.1039 for test that synthesis model is compatible \n## with a chi-squared test with 4 degrees of freedom.\n## \n## Confidence interval plot:"},{"path":"creating-synthetic-datasets.html","id":"summary","chapter":"2 Creating synthetic datasets","heading":"2.4 Summary","text":"tutorial, explored create synthetic data sets context scholarship teaching learning. often work sensitive data risk anonymity participants may prevent us accessing sharing data. Open scholarship practices recognise role value sharing research data, synthetic data sets can provide useful compromise scientific ethical responsibilities.created synthetic data sets smaller larger selection variables unpublished replication attempt Dunn (2014). assessing well synthetic data reconstructs observed data, general narrow utility measures. General utility measures include statistics like pMSE (propensity score mean-squared error), whereas narrow utility measures include comparing model parameters like regression coefficient confidence interval. saw performance worse greater mismatch recommended actual sample size, keep package recommendations mind creating synthetic data.tried provide relatively non-technical introduction synthetic data sets common world statistical agencies large granular data sets increase risk re-identification. resources, recommend primer Quintana (2020) included additional sections exploring different levels skew missing data affect synthetic data process. technical details, recommend original package article Nowok et al. (2016) synthpop website includes vignettes list resources learning synthetic data.final remember, always include label instructions informing readers provide synthetic data, mistake real observed data.","code":""},{"path":"creating-synthetic-datasets.html","id":"references","chapter":"2 Creating synthetic datasets","heading":"2.5 References","text":"Meyer, M. N. (2018). Practical Tips Ethical Data Sharing. Advances Methods Practices Psychological Science, 1(1), 131–144. https://doi.org/10.1177/2515245917747656Nowok, B., Raab, G. M., & Dibben, C. (2016). synthpop: Bespoke Creation Synthetic Data R. Journal Statistical Software, 74, 1–26. https://doi.org/10.18637/jss.v074.i11Quintana, D. S. (2020). synthetic dataset primer biobehavioural sciences promote reproducibility hypothesis generation. ELife, 9, e53275. https://doi.org/10.7554/eLife.53275Raab, G. M., Nowok, B., & Dibben, C. (2021). Assessing, visualizing improving utility synthetic data (arXiv:2109.12717). arXiv. https://doi.org/10.48550/arXiv.2109.12717Snoke, J., Raab, G. M., Nowok, B., Dibben, C., & Slavkovic, . (2018). General specific utility measures synthetic data. Journal Royal Statistical Society: Series (Statistics Society), 181(3), 663–688. https://doi.org/10.1111/rssa.12358Wickham, H. & Grolemund, G. (2017). R Data Science. O'Reilly.","code":""},{"path":"installing-r.html","id":"installing-r","chapter":"A Installing R","heading":"A Installing R","text":"Installing R RStudio usually straightforward. sections explain helpful YouTube video .","code":""},{"path":"installing-r.html","id":"installing-base-r","chapter":"A Installing R","heading":"A.1 Installing Base R","text":"Install base R. Choose download link operating system (Linux, Mac OS X, Windows).Mac, install latest release newest R-x.x.x.pkg link (legacy version older operating system). install R, also install XQuartz able use visualisation packages.installing Windows version, choose \"base\" subdirectory click download link top page. install R, also install RTools; use \"recommended\" version highlighted near top list.using Linux, choose specific operating system follow installation instructions.","code":""},{"path":"installing-r.html","id":"installing-rstudio","chapter":"A Installing R","heading":"A.2 Installing RStudio","text":"Go rstudio.com download RStudio Desktop (Open Source License) version operating system list titled Installers Supported Platforms.","code":""},{"path":"installing-r.html","id":"rstudio-settings","chapter":"A Installing R","heading":"A.3 RStudio Settings","text":"settings fix immediately updating RStudio. Go Global Options... Tools menu (⌘,), General tab, uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.may also want change appearance code. Different fonts themes can sometimes help visual difficulties dyslexia.\nFigure .1: RStudio General Appearance settings\nmay also want change settings Code tab. Foe example, Lisa prefers two spaces instead tabs code likes able see whitespace characters. matter personal preference.\nFigure .2: RStudio Code settings\n","code":""},{"path":"installing-r.html","id":"installing-latex","chapter":"A Installing R","heading":"A.4 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. course require make PDFs. generate PDF reports, additionally need install tinytex (Xie, 2022) run following code:","code":"\ntinytex::install_tinytex()"},{"path":"symbols.html","id":"symbols","chapter":"B Symbols","heading":"B Symbols","text":"\nFigure B.1: Image James Chapman/Soundimals\n","code":""},{"path":"conventions.html","id":"conventions","chapter":"C Conventions","heading":"C Conventions","text":"book use following conventions:Generic code: list(number = 1, letter = \"\")Highlighted code: dplyr::slice_max()File paths: data/sales.csvR Packages: tidyverseFunctions: paste()Strings: \"psyTeachR\"Numbers: 100, 3.14Logical values: TRUE, FALSEGlossary items: ordinalCitations: Wickham (2021)Internal links: Chapter 1External links: R Data ScienceMenu/interface options: New File...","code":""},{"path":"conventions.html","id":"webexercises","chapter":"C Conventions","heading":"C.1 Webexercises","text":"See webexercises details use materials.Type integer: going learn lot: TRUEFALSEWhat p-value?\n\nprobability null hypothesis truethe probability observed (extreme) data, assumption null-hypothesis truethe probability making error conclusion\nfound hidden text!","code":"\nprint(\"You found some hidden code!\")## [1] \"You found some hidden code!\""},{"path":"conventions.html","id":"alert-boxes","chapter":"C Conventions","heading":"C.2 Alert boxes","text":"Informational asides.Notes warn something.Notes things cause serious errors.Try .","code":""},{"path":"conventions.html","id":"code-chunks","chapter":"C Conventions","heading":"C.3 Code Chunks","text":"","code":"\n# code chunks\npaste(\"Applied\", \"Data\", \"Skills\", 1, sep = \" \")## [1] \"Applied Data Skills 1\"```{r setup, message = FALSE}\n# code chunks with visible r headers\nlibrary(tidyverse)```"},{"path":"conventions.html","id":"glossary","chapter":"C Conventions","heading":"C.4 Glossary","text":"","code":""},{"path":"glossary-1.html","id":"glossary-1","chapter":"D Glossary","heading":"D Glossary","text":"can use glossary() function automatically link term psyTeachR glossary make project-specific glossary.create link glossary include tooltip short definition hover term. Use following syntax inline r: glossary(\"word\"). example, common data types integer, double, character.need link definition, using different form word, add display version second argument (display). can also override automatic short definition providing third argument (def). Add argument link = FALSE just want hover definition link psyTeachR glossary.[1] \"Data Types\"can add glossary table end chapter following code. creates table terms used chapter previous glossary_table() function. uses kableExtra(), use code chunk, set results='asis'.want contribute glossary, fork github project, add terms submit pull request, suggest new term issues page.","code":"\nglossary(\"data type\", \n         display = \"Data Types\", \n         def = \"My custom definition of data types\", \n         link = FALSE)```{r, echo=FALSE, results='asis'}\nglossary_table()```"},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"book licensed Creative Commons Attribution-ShareAlike 4.0 International License (CC--SA 4.0). free share adapt book. must give appropriate credit (DeBruine, 2021), provide link license, indicate changes made. adapt material, must distribute contributions license original.","code":""},{"path":"references-1.html","id":"references-1","chapter":"References","heading":"References","text":"","code":""}]
